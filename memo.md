# タスク
- 学習データセットの形式や読み込み方法を確認する。(RGLDv2-cleanやそのILIASやUnEDでも確認したい→既に先行文献で行われている可能性大)
- RGLDv2-cleanデータセットに関して問い合わせる。
- 学習が適切に実施されるかを確認する。
- ※論文(AMES, SuperGlobal)を読んで新規手法を考えて実装する(Manus)。

# アイディア
- 自動で各専門モデルを切り替える研究はないかも
- 専門モデルのアーキテクチャで汎用データセットに通じるか見た研究はないかも。汎用検索に有効なアーキテクチャに関する研究はないかも。

# 方針策定
評価データと評価コードを論文で確認して提案手法を組み込めるか実装(比較手法が再実験されているのか先行文献から持ってきたのかを確認，Ciderとかで全部調べるのが良さそう。それだけで論文化できる設はある)→学習条件なども確認して提案手法が学習できるか試す(国分寺サーバーが使えるかもここで試す，学習を回せるような状態にするのが優先)→提案手法の概要と課題点を調べる。

※[SpCaの学習コード](https://github.com/Zy-Zhang/SpCa/blob/main/spca_train.py)を参考にしているはずだからそれと比較しながら適切な学習コードになっているか見る。
※学習コードとして

※発展的なプーリング＋バッチtransformer＋ランキング学習と等価な損失関数のような枠組みでなんとかならないものか


- manusで作成したコードで使えそうなやつ:
  - iris系列
    - "C:\Users\71812108\OneDrive - Hitachi Group\【社外発表】\論文\25下_論文\調査資料\manus\6_iris\iris_evaluate.py"
    - "C:\Users\71812108\OneDrive - Hitachi Group\【社外発表】\論文\25下_論文\調査資料\manus\6_iris\iris_train.py"
    - "C:\Users\71812108\OneDrive - Hitachi Group\【社外発表】\論文\25下_論文\調査資料\manus\8_6and7_training_and_eval\iris_modified\iris_implementation_corrected.py"
  - adaptive_hybrid系
    - C:\Users\71812108\OneDrive - Hitachi Group\【社外発表】\論文\25下_論文\調査資料\manus\7_AdaptiveHybridModel\adaptive_hybrid_retrieval.py
- 手法やデータセット選定の起点となる論文:
  - Global Features are All You Need for Image Retrieval and Reranking，ICCV2023 (少し毛色が異なる)
  →[評価データセット](https://chatgpt.com/share/68517c53-a41c-8009-a215-bc881cd4a7b2)は"ROxf （Revisited Oxford）","RPar （Revisited Paris）", "Google Landmarks v2"。
  - ULTRON: Unifying Local Transformer and  Convolution for Large-scale Image Retrieval
  →学習は明示的に行っていない。チューニングにROxf （Revisited Oxford）を用いており，評価データセットと同じと思われる(望ましくないのでは？)。
  →ネットワークに付け替え可能な形になっている。
  - Learning Spatial-context-aware Global Visual Feature Representation  for Instance Image Retrieval
  - Batch Transformer: Look for Attention in Batch (毛色は異なるが手法は有効の可能性が高い)
  - On Train-Test Class Overlap and Detection for Image Retrieval
  →公開されていない感あるが，非公式の個人アカウントでリリースされており謎
- 使用データセット:
  - Instance Image Retrievalの学習データは GLDv2 clean と RGLD v2 clean。
  - 汎用検索における学習データはUnED。
  - Instance Image Retrievalの評価データは[ROxf （Revisited Oxford）と RPar （Revisited Paris）](https://github.com/filipradenovic/revisitop#python)。
- 学習方法:
  - [SpCa or ULTRON or MadaCosの学習条件](https://chatgpt.com/share/68581164-7634-8009-bfc8-34153d4cb4b1)を基盤に進める。GeMのパラメータ調整学習についても参考にする (研究において，プーリングの工夫をする場合)。
  >学習コードは[SpCa](https://github.com/Mak-GIBA/SpCa/blob/main/spca_train.py#L127)のやつを使い，このコードでモデルを差し替えて運用できるようにする。
- 比較手法(暫定):
  - **SpCa**
  - **ULTRON**
  - **SuperGlobal**
  - SENet
  - GeM
  - MadaCos
  - **CVNet**
  - DOLG
  - DELG

<!-- - ベンチとする論文とプログラムを決めてそこを起点に研究を進める。先行文献で引用されている文献も辿る。
- 出願する学会にあたりを付ける。
- ベンチ研究候補と関連研究:
  - Unifying Deep Local and Global Features for  Image Search，ECCV2020 (最も引用数の多い論文。DELGとしてデファクトスタンダード化してる)
  - Global Features are All You Need for Image Retrieval and Reranking，ICCV2023
  - Learning Spatial-context-aware Global Visual Feature Representation  for Instance Image Retrieval，ICCV2023
  - AMES: Asymmetric and Memory-Efficient  Similarity Estimation for Instance-level Retrieval，ECCV2024

- 一旦関連論文を総ざらいして読む -->

# ※理解を助ける記事
- DELG:
  - https://deepsquare.jp/2020/09/delg/
  - https://qiita.com/taiga518/items/24c7abdb763a530b9a67
  - https://webbigdata.jp/post-7306/




# 画像検索タスクの課題感 by ChatGPT
了解しました。一般画像を対象としたimage-to-image画像検索の分野について、直近5年間の研究動向を踏まえた研究背景や課題感を整理します。代表的な論文を参照しつつ、検索精度、特徴表現、ロバスト性、計算効率、マルチモーダル対応などの観点も含めてまとめます。

調査が終わり次第、整理した内容をお伝えします。


# 一般画像に対するimage-to-image検索の研究動向と課題（2020〜2025年）

## 定義と技術的概要

&#x20;**図: 一般的な画像検索パイプラインの概略**（ユーザがクエリ画像を入力し、その特徴ベクトルをデータベース内の画像特徴と比較して類似画像を取得し、結果を返す）
**image-to-image画像検索**（コンテンツベース画像検索, CBIR）とは、クエリとして画像を入力し、その視覚的内容に基づいてデータベースから類似する画像を探し出す技術です。テキストに依存せず画像の内容特徴を直接用いる点で従来のテキストタグによる検索と異なり、色・質感・形状といった**低レベル特徴**や物体・シーンなどの**高レベル特徴**を解析して一致度を算出します。古くから研究されている分野ですが、高度化・大規模化する画像データに対し**効率的かつ高精度な検索**が依然求められており、近年は主にディープラーニングを用いたアプローチが主流です。

## 主要な研究トレンド（2020〜2025年）

近年（直近5年間）の一般画像を対象としたimage-to-image検索では、深層学習の発展に伴い以下のような研究トレンドが見られます。

### 深層特徴表現と画像埋め込み

2010年代後半以降、**畳み込みニューラルネットワーク（CNN）**による画像特徴抽出が従来の手法に取って代わり、画像を低次元のベクトル（グローバル記述子）にエンコードして高速検索する手法が確立しました。2019年以前から提案されていたMACやR-MAC、GeMプーリングといった手法はCNN最終層の特徴マップを集約して強力なグローバル特徴を生成します。近年の研究はこの**ディープ特徴**をさらに洗練し、高精度化のためにネットワーク構造の改良や学習戦略の工夫が行われています。例えば**ディープ metric learning**（距離学習）の手法では、画像ペアやトリプレットに基づく損失関数を用いて「類似画像は近く、異質な画像は遠く」なる特徴空間を教師あり学習します。その結果、画像検索精度が飛躍的に向上し、人工知能技術が画像検索を高度化していると報告されています。もっとも、精度向上と引き換えに計算コストが増大する傾向も指摘されており、後述する効率化も課題となっています。

### 自己教師あり学習による表現学習

ラベル付けデータの用意が難しい画像検索ドメインにおいて、**自己教師あり学習**（Self-Supervised Learning, SSL）は重要なトレンドです。2020年前後に提案されたSimCLRやMoCoといった手法は、大量の未ラベル画像からのコントラスト学習によって有用な画像特徴表現を学習できることを示しました。これらSSL手法は画像分類タスクで顕著な成果を挙げ、画像検索にも応用されています。しかし、画像検索（特にインスタンス検索）では**視点や背景の大きな変化にも不変な特徴**が求められるのに対し、従来のSSL手法で用いる自己生成の正例（拡張画像ペア）のみではその学習信号が不十分であることが指摘されています。そこでDengら(2022)はSimCLR拡張の**InsCLR**を提案し、バッチ内やメモリバンクから動的に類似画像ペアを擬似ラベル生成して学習することでロバストなインスタンス識別特徴を獲得しました。InsCLRは自己教師あり手法のみで従来の教師あり学習に匹敵する高精度な画像検索を実現し、従来SSL手法を上回る性能を示したと報告されています。このように自己教師あり学習は、データアノテーションの負担軽減とドメイン適応を目的として積極的に研究が進められています。

### Transformer系モデルの適用

視覚分野でもTransformerが台頭した近年、**Vision Transformer (ViT)** を画像検索に応用する試みも始まっています。Transformerは自己注意機構によりグローバルな文脈情報を捉えられる利点があり、画像分類ではCNNに匹敵する性能を示しています。2021年頃よりViTのオフザシェルフ特徴を画像検索に利用する研究や、Transformerを再ランキング（候補再排序）に用いる研究が現れました。しかし初期の研究ではCNNを凌駕する例はなく、専用の微調整や工夫が必要とされています。Songら(2023)は**DToP (Deep Token Pooling)** 手法を提案し、ViTの複数層から得た\[CLS]トークン（画像全体特徴）と局所パッチ特徴をそれぞれ統合する**二枝のプールニング機構**を導入しました。その結果、従来CNN+局所特徴の手法に比肩し、いくつかのデータセットでCNNベース手法を上回る初の成果を報告しています。このようにTransformerを用いた画像検索は萌芽的段階ですが、自己教師ありのViT (例えばDINO) を組み合わせる試みなども含め、今後の発展が期待されるトレンドです。

### マルチモーダル対応と意味的検索

画像と言語など異種のデータを統合する**マルチモーダル学習**の進展も、画像検索の高度化に寄与しています。特にOpenAIによる**CLIP**（Contrastive Language-Image Pre-training, 2021年）は、4億組もの画像とテキストの対応関係で構築したクロスモーダル埋め込み空間を提供しました。CLIPは画像とテキストを共通のベクトル空間にマッピングすることで、高度な**セマンティック検索**を実現しています。例えばテキストによる画像検索のみならず、画像同士の類似度計算にもテキストで培われた意味的な特徴が活用でき、従来の視覚特徴のみの比較では困難だった概念レベルでのマッチングが可能になります。実際、CLIPの画像エンコーダで得た埋め込みを用いて汎用画像データベースから意味的に関連する画像を検索する応用例も登場しています。そのほか、画像+テキストの組み合わせで検索クエリを指定する**複合条件画像検索**（例：「図中のこの物体に似た○○」）や、スケッチと写真を跨いだ検索など、マルチモーダル対応技術によって画像検索の柔軟性が拡大しています。

## 近年の代表的な研究論文と貢献

直近5年間に発表された一般画像検索に関する代表的な研究とその貢献内容を以下の表にまとめます。

| 論文（年）                           | アプローチ概要                                                      | 主な貢献内容                                                                                                                                             |
| ------------------------------- | ------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Caoら (ECCV 2020)** 「DELG」     | **Deep Local and Global Features**（CNNによるグローバル特徴+局所特徴の統合モデル） | 単一のCNNで画像全体の埋め込みと局所特徴検出を両立する枠組み(DELG)を提案。一般物体のクラスラベルのみで学習可能で、従来別々だったグローバル記述子と局所特徴を統合して高精度な検索を実現。ROxford/Parisベンチマークで当時のSOTA達成。                     |
| **Radfordら (ICML 2021)** 「CLIP」 | **クロスモーダル対比学習**（画像と言語のマルチモーダル事前学習モデル）                        | 4億組の画像-テキストペアによるコントラスト学習で汎用視覚と言語の埋め込み空間を構築。追加の学習無しでゼロショット分類・検索が可能となり、画像検索におけるセマンティックギャップを大きく緩和するポテンシャルを示した。                                        |
| **Dengら (AAAI 2022)** 「InsCLR」  | **自己教師ありコントラスト学習**（インスタンス検索特化のSSL手法）                         | 従来のSimCLRやMoCoでは不足していた視点変化への不変性獲得のため、バッチ内およびメモリバンクから擬似的にポジティブ対を発見する自己教師あり手法InsCLRを提案。大規模ランドマークデータで学習し、教師ありモデルに匹敵するインスタンス検索精度を達成した。                 |
| **Songら (WACV 2023)**           | **ViTによる特徴プーリング**（Transformer活用の画像検索モデル）                     | Vision Transformerのマルチ層出力からグローバル特徴と局所特徴を抽出し統合するDeep Token Pooling (DToP)手法を開発。従来のCNNベース手法を上回る初のTransformer画像検索モデルとして報告され、ViTの利点を生かした新たな性能向上策を示した。  |
| **Hanら (IJMIR 2022)**           | **クロスドメイン画像検索の総説**（異種ドメイン間の画像検索）                             | 可視画像と赤外画像、写真とスケッチなどドメインの異なる画像間での検索課題(CDIR)について包括的調査を実施。特徴空間変換と画像変換の2手法に分類し、各応用分野（衣料画像、リモートセンシング等）の研究動向を整理。異なるドメイン間ではドメイン不変な特徴表現の学習が主要な課題であることを示した。 |

## 画像検索における主な課題

近年の深層学習によって以前より高精度な画像検索が可能になった一方で、研究コミュニティでは以下のような**課題**が指摘されています。

* **セマンティックギャップ**: 人間が捉える高次の意味内容と、コンピュータが抽出できる低レベル特徴との隔たりを指します。例えば「犬」の画像を探す際、単純な色やテクスチャの一致では不十分です。ディープラーニングでギャップは縮小しましたが、それでも微妙な文脈や関係性の理解には限界があり、完全には解決していません。
* **ロバスト性（頑健性）**: 異なる撮影条件や視点、背景、遮蔽、ノイズなどの影響下でも、同一対象を正しくマッチングできる特徴の獲得が課題です。特にインスタンス検索では、物体の向きやスケール変化に対する不変性が重要ですが、十分な学習データや適切なデータ拡張がないと性能低下を招きます。モデルが\*\*攻撃的改変（adversarial）\*\*に対してどれだけ安定かというセキュリティ面も含め、ロバスト性確保が研究課題です。
* **スケーラビリティ（拡張性）**: Webやクラウド上には数億枚規模の画像コレクションが存在し、その中からリアルタイムに検索するための**検索アルゴリズムの拡張性**が求められます。計算量・メモリを削減するためのApproximate Nearest Neighbor（近似最近傍）探索、圧縮技術（例: 产品量子化）やディープハッシュ法の活用が進められていますが、データ規模の爆発的増大に追いつくスケーラビリティは依然として挑戦です。
* **クロスドメイン対応**: あるドメイン（例えば写真）で学習したモデルを別ドメイン（例えばイラストや赤外画像）に適用すると精度が著しく低下する場合があります。異なるドメイン間では分布や特徴表現にギャップがあるため、**ドメイン適応**や**不変特徴学習**が課題となります。近年、ドメイン間マッピングや特徴空間のアライメント手法が研究されていますが、汎用的に機能するモデル構築には未解決の問題が残ります。
* **計算効率と検索速度**: 高精度化のためモデルが大型化・特徴次元が増大すると、検索に要する時間や計算資源も増えがちです。実システムでは**精度と効率のバランス**が重要であり、いかに高速に類似度計算・ランキングを行うか、インデックス構築を高速化するかが課題です。GPUによるベクトル検索や分散処理、特徴の低次元圧縮、軽量ネットワーク設計など様々なアプローチで効率向上が模索されています。
* **データアノテーションと評価**: 教師あり学習には大量のラベル付きデータ（あるいはペア画像による関連性ラベル）が必要ですが、汎用画像で網羅的なアノテーションを行うのは現実的ではありません。そのため自己教師あり学習や弱教師あり学習でどこまで対応できるかが課題です。また、検索システムの評価指標（平均適合率MAPなど）は定まっているものの、ユーザの主観的満足度との乖離もあり、より人間の意図に沿った評価・フィードバック手法（例: **インタラクティブな関連フィードバック**）の重要性も指摘されています。

## 今後の研究の方向性と未解決課題

上述の課題を踏まえ、2025年時点で考えられる今後の研究方向性や未解決の問題点を整理します。

* **高次元の意味理解とギャップ解消**: 人間並みの画像理解に近づくため、画像特徴にテキストや知識グラフの情報を組み合わせて**意味的な埋め込み空間**を構築する研究が進むでしょう。例えばCLIPのような巨大マルチモーダルモデルを画像検索に取り入れ、視覚と言語の双方から意味を捉えることでセマンティックギャップを縮小する方向性です。さらに、大規模言語モデル(LLM)と視覚モデルを組み合わせて、検索結果の理由説明や高度なクエリ解釈を行うマルチエージェント的なシステムも将来検討されています。

* **ロバストかつ汎用的な特徴学習**: あらゆる環境下でも安定した特徴表現を得るため、より多様なデータ拡張やシミュレーション、自己教師あり手法の改良が続くでしょう。特にInsCLRのように**擬似ラベルによる学習**や、敵対的攻撃に耐性のある**不確実性推定付きモデル**（例: Evidential Transformer）など、ロバスト性を強化する研究が期待されます。また、単一モデルが複数ドメインに対応できる**ドメイン統合学習**も重要な課題です。スタイル変換やドメイン適応技術と組み合わせて、訓練された分布を超えた一般化性能を持つモデル構築が模索されるでしょう。

* **大規模データへのスケーラブルな検索**: データセット規模がさらに拡大する中、検索アルゴリズムのスケーラビリティ向上が不可欠です。今後は**学習によるインデックス構築**（機械学習で最適化された近似最近傍探索構造）や、ハードウェアアクセラレーション（ベクトルデータベース専用機器など）の活用が進むと考えられます。分散システム上での並列検索や、モバイル・エッジ環境での効率的検索も課題であり、軽量かつ高速なモデルの設計（蒸留や量子化によるモデル圧縮）が引き続き研究されるでしょう。

* **ユーザ意図の反映とインタラクティブ検索**: 完全自動の検索性能向上に加え、ユーザからのフィードバックをリアルタイムに取り入れて結果を改善する**対話型の画像検索**も注目されています。関連フィードバック(Relevance Feedback)自体は古くから研究されていますが、深層学習と組み合わせることでユーザの意図を学習し再ランキングに反映する高度な手法が提案されています。今後はユーザが求める類似性の種類（外見の類似、意味的関連、感性的評価など）を動的に汲み取るシステムや、検索過程を説明可能にするアプローチが発展するでしょう。

以上のように、2020年から2025年にかけての一般画像のimage-to-image検索研究は、深層学習による性能向上を中心に大きく前進しました。しかし**高次の視覚理解**や**汎用性**、**効率性**などの観点で依然課題が残っており、今後も自己教師あり学習やTransformer、マルチモーダルAIの力を借りつつこれら課題解決に向けた研究が継続すると考えられます。 이미지 검색技術の発展により、より直感的で高度な情報検索が可能になる未来が期待されています。


